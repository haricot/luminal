; GLUMoE: Match the expert computation subgraph of a Gated MoE (SwiGLU variant).
;
; This matches the pattern produced by QwenMoE::forward() starting from the
; expert gathers through to the final weighted sum, and replaces it with a
; fused GLUMoE HostOp.
;
; Inputs extracted:
;   ?x            - input activations [s, H] F32
;   ?topk_idx     - top-k expert indices [s, k] Int (from argsort+slice)
;   ?topk_vals    - top-k routing values [s, k] F32 (from gather on softmax)
;   ?gate_up_w    - stacked gate+up expert weights [E, intermediate*2, H] BF16
;   ?down_w       - stacked down expert weights [E, H, intermediate] BF16
;
; The pattern captures:
;   1. Gate-up expert gather (Iota, Mul, Cast, Iota, Cast, Add, Cast, Gather)
;   2. Cast BF16→F32 of gathered gate-up weights
;   3. Gate-up batched matmul (Mul + SumReduce)
;   4. Gate/Up split via Iota+Gather (slice semantics)
;   5. SwiGLU: silu(gate) * up
;   6. Down expert gather (same pattern as gate-up)
;   7. Cast BF16→F32 of gathered down weights
;   8. Down batched matmul (Mul + SumReduce)
;   9. Weighted sum: (down_out * topk_values) summed over k
;
; Variables with ? prefix are egglog pattern variables.
; We use wildcards (?_xxx) for shapes/strides we don't extract.

(rule
    (
        ; ===== Gate-up expert gather =====
        ; t51: Iota for base index (expert_idx * io_gu)
        (= ?gu_iota_base (Iota ?gu_io ?gu_iota_base_range))
        ; t52: Mul topk_indices * io → base offsets [s, k]
        (= ?gu_mul_base (Mul ?gu_mul_base_shape ?topk_idx ?gu_mul_base_a_stride ?gu_iota_base ?gu_mul_base_b_stride ?gu_mul_base_out_stride))
        ; t53: Cast to F32
        (= ?gu_cast_base (Cast ?gu_mul_base ?gu_cast_base_size (F32)))
        ; t54: Iota for within-expert index
        (= ?gu_iota_within (Iota (MIter) ?gu_iota_within_range))
        ; t55: Cast within to F32
        (= ?gu_cast_within (Cast ?gu_iota_within ?gu_cast_within_size (F32)))
        ; t56: Add base + within → flat gather indices
        (= ?gu_add_idx (Add ?gu_add_shape ?gu_cast_base ?gu_add_a_stride ?gu_cast_within ?gu_add_b_stride ?gu_add_out_stride))
        ; t57: Cast to Int
        (= ?gu_cast_idx (Cast ?gu_add_idx ?gu_cast_idx_size (Int)))
        ; t58: Gather gate_up weights
        (= ?gu_gathered (Gather ?gu_cast_idx ?gu_gather_idx_shape ?gu_gather_idx_stride ?gate_up_w ?gu_gather_data_shape ?gu_gather_data_stride))

        ; ===== Cast BF16→F32 =====
        ; t59: Cast gathered gate_up to F32
        (= ?gu_f32 (Cast ?gu_gathered ?gu_f32_size (F32)))

        ; ===== Gate-up batched matmul =====
        ; t60: Mul x * gathered_gu (broadcast multiply)
        (= ?gu_matmul_mul (Mul ?gu_matmul_mul_shape ?x ?gu_matmul_a_stride ?gu_f32 ?gu_matmul_b_stride ?gu_matmul_mul_out_stride))
        ; t61: SumReduce over K dimension
        (= ?gu_matmul (Sum ?gu_matmul_out_shape ?gu_matmul_k ?gu_matmul_mul ?gu_matmul_in_stride ?gu_matmul_k_stride ?gu_matmul_out_stride))

        ; ===== Up slice via Iota+Gather =====
        ; t62: Iota with complex expression (slicing the "up" half)
        (= ?up_iota (Iota ?up_iota_expr ?up_iota_range))
        ; t63: Gather to select up portion from matmul result
        (= ?up_slice (Gather ?up_iota ?up_gather_idx_shape ?up_gather_idx_stride ?gu_matmul ?up_gather_data_shape ?up_gather_data_stride))

        ; ===== SwiGLU: silu(gate) * up =====
        ; t64: Constant(-1)
        (= ?neg1 (Constant -1.000000))
        ; t65: gate * -1
        (= ?neg_gate (Mul ?silu_shape1 ?gu_matmul ?silu_a_stride1 ?neg1 ?silu_b_stride1 ?silu_out_stride1))
        ; t66: Constant(log2e)
        (= ?log2e (Constant 1.442695))
        ; t67: neg_gate * log2e
        (= ?scaled (Mul ?silu_shape2 ?neg_gate ?silu_a_stride2 ?log2e ?silu_b_stride2 ?silu_out_stride2))
        ; t68: exp2
        (= ?exp2_val (Exp2 ?silu_shape3 ?scaled ?silu_in_stride3 ?silu_out_stride3))
        ; t69: Constant(1)
        (= ?one (Constant 1.000000))
        ; t70: exp2 + 1
        (= ?plus1 (Add ?silu_shape4 ?exp2_val ?silu_a_stride4 ?one ?silu_b_stride4 ?silu_out_stride4))
        ; t71: recip
        (= ?sigmoid (Recip ?silu_shape5 ?plus1 ?silu_in_stride5 ?silu_out_stride5))
        ; t72: gate * sigmoid(gate) = silu(gate)
        (= ?silu_out (Mul ?silu_shape6 ?gu_matmul ?silu_a_stride6 ?sigmoid ?silu_b_stride6 ?silu_out_stride6))
        ; t73: silu(gate) * up
        (= ?swiglu_out (Mul ?swiglu_shape ?silu_out ?swiglu_a_stride ?up_slice ?swiglu_b_stride ?swiglu_out_stride))

        ; ===== Down expert gather =====
        ; t74: Iota for base index (expert_idx * io_down)
        (= ?dn_iota_base (Iota ?dn_io ?dn_iota_base_range))
        ; t75: Mul topk_indices * io_down
        (= ?dn_mul_base (Mul ?dn_mul_base_shape ?topk_idx ?dn_mul_base_a_stride ?dn_iota_base ?dn_mul_base_b_stride ?dn_mul_base_out_stride))
        ; t76: Cast to F32
        (= ?dn_cast_base (Cast ?dn_mul_base ?dn_cast_base_size (F32)))
        ; t77: Iota for within-expert index
        (= ?dn_iota_within (Iota (MIter) ?dn_iota_within_range))
        ; t78: Cast within to F32
        (= ?dn_cast_within (Cast ?dn_iota_within ?dn_cast_within_size (F32)))
        ; t79: Add base + within
        (= ?dn_add_idx (Add ?dn_add_shape ?dn_cast_base ?dn_add_a_stride ?dn_cast_within ?dn_add_b_stride ?dn_add_out_stride))
        ; t80: Cast to Int
        (= ?dn_cast_idx (Cast ?dn_add_idx ?dn_cast_idx_size (Int)))
        ; t81: Gather down weights
        (= ?dn_gathered (Gather ?dn_cast_idx ?dn_gather_idx_shape ?dn_gather_idx_stride ?down_w ?dn_gather_data_shape ?dn_gather_data_stride))

        ; ===== Cast BF16→F32 =====
        ; t82: Cast gathered down to F32
        (= ?dn_f32 (Cast ?dn_gathered ?dn_f32_size (F32)))

        ; ===== Down batched matmul =====
        ; t83: Mul swiglu_out * gathered_down (broadcast multiply)
        (= ?dn_matmul_mul (Mul ?dn_matmul_mul_shape ?swiglu_out ?dn_matmul_a_stride ?dn_f32 ?dn_matmul_b_stride ?dn_matmul_mul_out_stride))
        ; t84: SumReduce
        (= ?dn_matmul (Sum ?dn_matmul_out_shape ?dn_matmul_k ?dn_matmul_mul ?dn_matmul_in_stride ?dn_matmul_k_stride ?dn_matmul_out_stride))

        ; ===== Weighted sum over k experts =====
        ; t85: Mul down_out * topk_values
        (= ?weighted (Mul ?weighted_shape ?dn_matmul ?weighted_a_stride ?topk_vals ?weighted_b_stride ?weighted_out_stride))
        ; t86: SumReduce over k dimension → [s, H]
        (= ?output (Sum ?output_shape ?output_k ?weighted ?output_in_stride ?output_k_stride ?output_out_stride))
    )
    (
        (let ?glumoe (GLUMoE ?x ?topk_idx ?topk_vals ?gate_up_w ?down_w
            ?gu_io ?dn_io ?gu_matmul_k ?dn_matmul_k ?output_k
            ?gu_iota_within_range ?dn_iota_within_range))
        (union ?output ?glumoe)
    )
    :name "GLUMoE fused expert computation"
)
